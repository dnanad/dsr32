{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE3YdeaO9Nlo"
      },
      "source": [
        "# Using Gensim to create word embeddings.\n",
        "\n",
        "In this notebook we will use Gensime to create word embeddings from a corpus.\n",
        "\n",
        "---\n",
        "\n",
        "Firstly, we download the corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UDWyeCTcGbF_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget -nc \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%201%20-%20The%20Philosopher's%20Stone.txt\"\n",
        "!wget -nc \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%202%20-%20The%20Chamber%20of%20Secrets.txt\"\n",
        "!wget -nc \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%203%20-%20The%20Prisoner%20of%20Azkaban.txt\"\n",
        "!wget -nc \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%204%20-%20The%20Goblet%20of%20Fire.txt\"\n",
        "!wget -nc \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%205%20-%20The%20Order%20of%20the%20Phoenix.txt\"\n",
        "!wget -nc \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%206%20-%20The%20Half%20Blood%20Prince.txt\"\n",
        "!wget -nc \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%207%20-%20The%20Deathly%20Hallows.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w7EsFY_LGkST"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du12KNBf9eE9"
      },
      "source": [
        "## Import all necessary modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cPxWl1qt9b_b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\DAnand\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import logging\n",
        "import os\n",
        "import multiprocessing\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from scipy import spatial\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chO2MMAB9pnJ"
      },
      "source": [
        "## Train Gensim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "v0pFRf0JGcZ0"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "__init__() got an unexpected keyword argument 'size'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [11], line 24\u001b[0m\n\u001b[0;32m     19\u001b[0m                     \u001b[39myield\u001b[39;00m simple_preprocess(sentence)\n\u001b[0;32m     22\u001b[0m sentences \u001b[39m=\u001b[39m Sentences()\n\u001b[1;32m---> 24\u001b[0m model \u001b[39m=\u001b[39m Word2Vec(\n\u001b[0;32m     25\u001b[0m     sg\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     26\u001b[0m     size\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m,\n\u001b[0;32m     27\u001b[0m     window\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[0;32m     28\u001b[0m     min_count\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[0;32m     29\u001b[0m     workers\u001b[39m=\u001b[39;49mmultiprocessing\u001b[39m.\u001b[39;49mcpu_count())\n\u001b[0;32m     31\u001b[0m model\u001b[39m.\u001b[39mbuild_vocab(sentences)\n\u001b[0;32m     33\u001b[0m model\u001b[39m.\u001b[39mtrain(sentences\u001b[39m=\u001b[39msentences, total_examples\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mcorpus_count, epochs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
            "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'size'"
          ]
        }
      ],
      "source": [
        "class Sentences(object):\n",
        "    def __init__(self):\n",
        "        self.sentence_count = 0\n",
        "        self.epoch = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        print(f\"Epoch {self.epoch}\")\n",
        "        self.epoch += 1\n",
        "\n",
        "        files = os.listdir(\"./corpus/\")\n",
        "        files = [file for file in files if file.endswith(\".txt\")]\n",
        "        for fname in files:\n",
        "            with open(fname) as f_input:\n",
        "                corpus = f_input.read()\n",
        "            raw_sentences = sent_tokenize(corpus)\n",
        "            for sentence in raw_sentences:\n",
        "                if len(sentence) > 0:\n",
        "                    self.sentence_count += 1\n",
        "                    yield simple_preprocess(sentence)\n",
        "\n",
        "\n",
        "sentences = Sentences()\n",
        "\n",
        "model = Word2Vec(\n",
        "    sg=1,\n",
        "    size=300,\n",
        "    window=20,\n",
        "    min_count=3,\n",
        "    workers=multiprocessing.cpu_count())\n",
        "\n",
        "model.build_vocab(sentences)\n",
        "\n",
        "model.train(sentences=sentences, total_examples=model.corpus_count, epochs=5)\n",
        "\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY4d0XOm9tyW"
      },
      "source": [
        "## Find most similar words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ9oSWSZGf7l"
      },
      "outputs": [],
      "source": [
        "model.wv.most_similar(\"expelliarmus\", topn=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyt_EaVm9wtc"
      },
      "source": [
        "## Plot word similarities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSh3oR5WIV-Q"
      },
      "outputs": [],
      "source": [
        "def plot_similarities(words):\n",
        "    features = [np.array(model.wv[word]) for word in words]\n",
        "    \n",
        "    similarities = np.zeros((len(features), len(features)))\n",
        "    for index1, feature1 in enumerate(features):\n",
        "        for index2, feature2 in enumerate(features):\n",
        "            similarities[index1, index2] = 1 - spatial.distance.cosine(feature1, feature2)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 12))\n",
        "    g = sns.heatmap(\n",
        "        similarities,\n",
        "        annot=True,\n",
        "        xticklabels=words,\n",
        "        yticklabels=words,\n",
        "        cmap=\"inferno\"\n",
        "    )\n",
        "    g.set_xticklabels(words, rotation=90)\n",
        "    g.set_yticklabels(words, rotation=0)\n",
        "    g.set_title(\"Semantic Similarity\")\n",
        "            \n",
        "words = [\n",
        "    \"harry\",\n",
        "    \"hermione\",\n",
        "    \"ron\",\n",
        "    \"fred\",\n",
        "    \"george\",\n",
        "    \"snape\",\n",
        "    \"wand\",\n",
        "    \"snitch\",\n",
        "    \"marauder\",\n",
        "    \"map\",\n",
        "    \"hogwarts\",\n",
        "    \"slytherin\",\n",
        "    \"gryffindor\",\n",
        "    \"hufflepuff\",\n",
        "    \"ravenclaw\",\n",
        "    \"voldemort\",\n",
        "    \"tom\",\n",
        "    \"horcrux\",\n",
        "    \"snake\",\n",
        "    \"nagini\",\n",
        "    \"wizard\",\n",
        "    \"witch\"\n",
        "]\n",
        "plot_similarities(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX9onfgV93w0"
      },
      "source": [
        "# Thank you!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdL4Fi8H-wVB"
      },
      "outputs": [],
      "source": [
        "    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('tf-gpu')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "427e441da2c8bf2469802b3fbcdf5a7b4db2a3be41d0a73f73871bdac74d3741"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
